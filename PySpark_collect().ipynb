{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d78143d-4a28-4e87-8255-8986e51a833a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Collect() â€“ Retrieve data from DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c193dca6-9fca-4e24-93a4-9751b88a8b69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " PySpark RDD/DataFrame collect() is an action operation that is used to retrieve all the elements of the dataset (from all nodes) to the driver node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4408464a-b485-4e81-b26d-6e4fd967ce22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark_Collect()\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a219c247-7956-4882-ae28-52cdf057e5de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|  dptName|dptId|\n+---------+-----+\n|  Finance|   10|\n|Marketing|   20|\n|    Sales|   30|\n|       IT|   40|\n+---------+-----+\n\nroot\n |-- dptName: string (nullable = true)\n |-- dptId: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40) ]\n",
    "columns = [\"dptName\",\"dptId\"]\n",
    "df = spark.createDataFrame(dept,columns)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad22539-e8d6-410b-8d9b-4d3ec387b2de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(dptName='Finance', dptId=10), Row(dptName='Marketing', dptId=20), Row(dptName='Sales', dptId=30), Row(dptName='IT', dptId=40)]\n"
     ]
    }
   ],
   "source": [
    "print(df.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac3bc69a-e154-46e3-9093-457c7e1d1482",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance,10\nMarketing,20\nSales,30\nIT,40\n"
     ]
    }
   ],
   "source": [
    "for row in df.collect():\n",
    "    print(row['dptName'] + \",\" +str(row['dptId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ead4722-8013-4675-8480-4636bb5c2b23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: Row(dptName='Finance', dptId=10)"
     ]
    }
   ],
   "source": [
    "#returns the first element in an array (1st row)\n",
    "df.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10723e22-e86e-4e0a-b87d-7b7706de3fac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: 'Finance'"
     ]
    }
   ],
   "source": [
    "#returns the value of the first row & first column.\n",
    "df.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563ebe46-cd5a-4a85-b52c-4e71ec8800f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(dptName='Finance'), Row(dptName='Marketing'), Row(dptName='Sales'), Row(dptName='IT')]\n"
     ]
    }
   ],
   "source": [
    "df_col = df.select(\"dptName\").collect()\n",
    "print(df_col)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark_collect()",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
