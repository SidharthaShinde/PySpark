{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a7e67cd-5a43-481d-8479-a3c3c83e98e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark withColumn() Usage with Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bd189c9-a19d-4ff0-af4a-b676de9ea0f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "PySpark withColumn() is a transformation function of DataFrame which is used to change the value, convert the datatype of an existing column, create a new column, and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ad65f9e-f8e8-4b1f-b894-ee2e79f7445b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_withColumn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f28425-1b6b-4707-8744-777e002e5242",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  3500|\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',3500)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff97bfff-5293-424c-8ec9-cab6618d4f31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Change DataType using PySpark withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f844133f-7a93-43f0-9fec-4d7d3d9a0aad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  3500|\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62a3e585-ca75-47eb-a71d-eed3fa51dacc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Update The Value of an Existing Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7447f4-d3b6-4968-8826-787f1a0c881d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  4000|\n|  Michael|      Rose|        |2000-05-19|     M|  5000|\n|   Robert|          |Williams|1978-09-05|     M|  5000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  5000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  4500|\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary\",col(\"salary\")+1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8c69f62-1540-4c3d-a522-29fbbb456e9d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Create a Column from an Existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f3447c1-8e0e-4eb7-997f-0689126280f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-----+\n|firstname|middlename|lastname|       dob|gender|salary|bonus|\n+---------+----------+--------+----------+------+------+-----+\n|    James|          |   Smith|1991-04-01|     M|  3000|300.0|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|400.0|\n|   Robert|          |Williams|1978-09-05|     M|  4000|400.0|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|400.0|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  3500|350.0|\n+---------+----------+--------+----------+------+------+-----+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- bonus: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"bonus\",col(\"salary\")/10)\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ee2bbe3-9be4-42f4-a131-6db10afb980f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Add a New Column using withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6575c7d-6f6f-4810-98cb-667481c07c37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-----+----+\n|firstname|middlename|lastname|       dob|gender|salary|bonus|city|\n+---------+----------+--------+----------+------+------+-----+----+\n|    James|          |   Smith|1991-04-01|     M|  3000|300.0|pune|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|400.0|pune|\n|   Robert|          |Williams|1978-09-05|     M|  4000|400.0|pune|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|400.0|pune|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1| -0.1|pune|\n+---------+----------+--------+----------+------+------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df3 = df2.withColumn(\"city\",lit(\"pune\"))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ff0dbc4-1e37-4250-9cf8-ddf880f8b4af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Rename Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1b1b79-e1fc-45cf-86ac-dd00a7e145ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+---+------+-----+----+\n|firstname|middlename|lastname|       dob|Sex|salary|bonus|city|\n+---------+----------+--------+----------+---+------+-----+----+\n|    James|          |   Smith|1991-04-01|  M|  3000|300.0|pune|\n|  Michael|      Rose|        |2000-05-19|  M|  4000|400.0|pune|\n|   Robert|          |Williams|1978-09-05|  M|  4000|400.0|pune|\n|    Maria|      Anne|   Jones|1967-12-01|  F|  4000|400.0|pune|\n|      Jen|      Mary|   Brown|1980-02-17|  F|    -1| -0.1|pune|\n+---------+----------+--------+----------+---+------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "df3.withColumnRenamed(\"gender\",\"Sex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d350da23-e3ac-4001-b966-79445c8cb617",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###  Drop Column From PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25702e7-03ea-4e26-804a-08c804a40fe9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----+\n|firstname|middlename|lastname|       dob|gender|salary|city|\n+---------+----------+--------+----------+------+------+----+\n|    James|          |   Smith|1991-04-01|     M|  3000|pune|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|pune|\n|   Robert|          |Williams|1978-09-05|     M|  4000|pune|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|pune|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|pune|\n+---------+----------+--------+----------+------+------+----+\n\n"
     ]
    }
   ],
   "source": [
    "df3.drop(\"bonus\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3527b64b-2e0e-4b05-8e8d-f311d3d4eaf5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-----+----+\n|firstname|middlename|lastname|       dob|gender|salary|bonus|city|\n+---------+----------+--------+----------+------+------+-----+----+\n|    James|          |   Smith|1991-04-01|     M|  3000|300.0|pune|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|400.0|pune|\n|   Robert|          |Williams|1978-09-05|     M|  4000|400.0|pune|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|400.0|pune|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1| -0.1|pune|\n+---------+----------+--------+----------+------+------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f6607f0-f73d-4634-8812-b37705168503",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-----+----+------+\n|firstname|middlename|lastname|       dob|gender|salary|bonus|city|   sex|\n+---------+----------+--------+----------+------+------+-----+----+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|300.0|pune|  male|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|400.0|pune|  male|\n|   Robert|          |Williams|1978-09-05|     M|  4000|400.0|pune|  male|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|400.0|pune|female|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1| -0.1|pune|female|\n+---------+----------+--------+----------+------+------+-----+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df3.withColumn(\"sex\",when(df[\"gender\"] == 'M', \"male\").when(df[\"gender\"] == 'F', \"female\").otherwise(\"Not Vailable\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c21458f-c119-4152-8ef6-6780518c24a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark_withColumn()",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
